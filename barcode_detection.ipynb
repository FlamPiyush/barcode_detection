{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Importing Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import numpy as np\r\n",
    "import imutils\r\n",
    "import cv2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initializing video-frame and reading template image"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vid = cv2.VideoCapture(0)\r\n",
    "template = cv2.imread('template.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "\r\n",
    "while(True):\r\n",
    "    '''Starting loop for  capturing video frame'''   \r\n",
    "    \r\n",
    "    ret, frame = vid.read()\r\n",
    "    \r\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\r\n",
    "    # compute the Scharr gradient magnitude representation of the images\r\n",
    "    # in both the x and y direction using OpenCV 2.4\r\n",
    "    ddepth = cv2.cv.CV_32F if imutils.is_cv2() else cv2.CV_32F\r\n",
    "    gradX = cv2.Sobel(gray, ddepth=ddepth, dx=1, dy=0, ksize=-1)\r\n",
    "    gradY = cv2.Sobel(gray, ddepth=ddepth, dx=0, dy=1, ksize=-1)\r\n",
    "    # subtract the y-gradient from the x-gradient\r\n",
    "    gradient = cv2.add(gradX, gradY)\r\n",
    "    gradient = cv2.convertScaleAbs(gradient)\r\n",
    "    blurred = cv2.blur(gradient, (3, 3))\r\n",
    "    (_, thresh) = cv2.threshold(blurred, 225, 255, cv2.THRESH_BINARY)\r\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (21, 7))\r\n",
    "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\r\n",
    "    closed = cv2.erode(closed, None, iterations = 1)\r\n",
    "    closed = cv2.dilate(closed, None, iterations = 6)\r\n",
    "    cnts = cv2.findContours(closed.copy(), cv2.RETR_EXTERNAL,\r\n",
    "            cv2.CHAIN_APPROX_SIMPLE)\r\n",
    "    cnts = imutils.grab_contours(cnts)\r\n",
    "    if(len(cnts)!=0):\r\n",
    "        c = sorted(cnts, key = cv2.contourArea, reverse = True)[0]\r\n",
    "        # compute the rotated bounding box of the largest contour\r\n",
    "        rect = cv2.minAreaRect(c)\r\n",
    "        box = cv2.cv.BoxPoints(rect) if imutils.is_cv2() else cv2.boxPoints(rect)\r\n",
    "        box = np.int0(box)\r\n",
    "        # draw a bounding box arounded the detected barcode and display the\r\n",
    "        # image\r\n",
    "        cv2.drawContours(frame, [box], -1, (0, 255, 0), 3)\r\n",
    "       \r\n",
    "        result = cv2.matchTemplate(frame, template, cv2.TM_CCOEFF_NORMED)\r\n",
    "    cv2.imshow(\"Image\", closed)\r\n",
    "    cv2.imshow(\"Image1\", frame)\r\n",
    "#     cv2.imshow(\"TemplateMatching\",result)\r\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\r\n",
    "        break\r\n",
    "# After the loop release the cap object\r\n",
    "vid.release()\r\n",
    "# Destroy all the windows\r\n",
    "cv2.destroyAllWindows()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "import numpy as np\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "img = frame\r\n",
    "img2 = img.copy()\r\n",
    "template = cv2.imread('template.png')\r\n",
    "result = cv2.matchTemplate(img, template, cv2.TM_CCOEFF_NORMED)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('cbir': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "e793a7d7b892b7f9b399d1144dda67d15111a4718fdb44d06ba629bf8b690210"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}